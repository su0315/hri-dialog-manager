{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building an Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # number of pentomino pieces\n",
    "        no_pieces = 9 # + 1 + 1 #pieces + uncertainty + lang team\n",
    "        \n",
    "        #self.uncertainty_action = 10\n",
    "        #self.lang_action = 11\n",
    "        \n",
    "        # ACTIONS\n",
    "        '''for now: we only decide for one coordinate --> no of actions = number of coordinates)\n",
    "        (for later: we only decide for one coordinate out of all absolute coordinates and moving coordinate, \n",
    "        boolean value expressing uncertainty)'''\n",
    "        self.action_space = Discrete(no_pieces)\n",
    "        \n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=0, high=100, shape=(no_pieces,))   ## it was shape = 1 before\n",
    "        \n",
    "        # POSSIBLE STATES\n",
    "        '''Set start state (in our case start state is the only state and here we need to get our training data in or \n",
    "        construct a random formula that will randomly generate possible scenarios each time the function is called.\n",
    "        for now: create random probabilities for 9 coordinates that add up to one\n",
    "        uplevel: do the same and make sure that all follow the true distribution which is p=1 for the gold_coordinate and p=0 for all others\n",
    "        uplevel: do the same + add possiblity for moving vector'''\n",
    "        #no_pieces = 9\n",
    "        self.p_gold  = [0.0 for i in range(no_pieces-1)] + [1.0]\n",
    "        random.shuffle(self.p_gold)\n",
    "\n",
    "\n",
    "        noise_std = 100\n",
    "        p_noise = [np.abs(np.random.normal(scale = noise_std, loc = i)) for i in self.p_gold]\n",
    "        smax = [i/np.sum(p_noise) for i in p_noise]\n",
    "\n",
    "        self.state = smax\n",
    " \n",
    "        \n",
    "    def step(self, action):\n",
    "        '''Our actions do not affect our state, because we only have one state, the start state. Also we don't need \n",
    "        the shower_length which represents the lenght of the sequence, but at the end we use it in the evalulation-\n",
    "        function soo .. dunno.\n",
    "        '''\n",
    "    \n",
    "\n",
    "        if action == np.argmax(self.p_gold):\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "        \n",
    "        # Check if sequence is done\n",
    "        '''we have a sequence of one state: the output that the other groups give us. based on that \n",
    "        we make a decision and a new round starts. so we don't need to count down the seconds of a 60min long\n",
    "        shower to know when a round is over.'''\n",
    "        done = True\n",
    "        \n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        '''Reset start state (output of previous groups) when new round starts (use \"random-formula\" that we need to \n",
    "        create above)'''\n",
    "        #bleh = [random.uniform(0, 0.628) for _ in range(8)]\n",
    "        #bleh.append(random.uniform(2, 5))\n",
    "        #self.state = np.exp(bleh)/np.sum(np.exp(bleh))\n",
    "        \n",
    "                # number of pentomino pieces\n",
    "        no_pieces = 9 # + 1 + 1 #pieces + uncertainty + lang team\n",
    "        \n",
    "        #self.uncertainty_action = 10\n",
    "        #self.lang_action = 11\n",
    "        \n",
    "        # ACTIONS\n",
    "        '''for now: we only decide for one coordinate --> no of actions = number of coordinates)\n",
    "        (for later: we only decide for one coordinate out of all absolute coordinates and moving coordinate, \n",
    "        boolean value expressing uncertainty)'''\n",
    "        self.action_space = Discrete(no_pieces)\n",
    "        \n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=0, high=100, shape=(no_pieces,))   ## it was shape = 1 before\n",
    "        \n",
    "        # POSSIBLE STATES\n",
    "        '''Set start state (in our case start state is the only state and here we need to get our training data in or \n",
    "        construct a random formula that will randomly generate possible scenarios each time the function is called.\n",
    "        for now: create random probabilities for 9 coordinates that add up to one\n",
    "        uplevel: do the same and make sure that all follow the true distribution which is p=1 for the gold_coordinate and p=0 for all others\n",
    "        uplevel: do the same + add possiblity for moving vector'''\n",
    "        #no_pieces = 9\n",
    "        self.p_gold  = [0.0 for i in range(no_pieces-1)] + [1.0]\n",
    "        random.shuffle(self.p_gold)\n",
    "\n",
    "\n",
    "        noise_std = 100  \n",
    "        p_noise = [np.abs(np.random.normal(scale = noise_std, loc = i)) for i in self.p_gold]\n",
    "        smax = [i/np.sum(p_noise) for i in p_noise]\n",
    "\n",
    "        self.state = smax\n",
    "\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLARA\n",
    "#env.observation_space \n",
    "#env.observation_space.sample()\n",
    "#env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11800315187075001,\n",
       " 0.15397184111856263,\n",
       " 0.12730024338499382,\n",
       " 0.040599978086624765,\n",
       " 0.31851661857336744,\n",
       " 0.025934738348204908,\n",
       " 0.15509614585661943,\n",
       " 0.008037654228970235,\n",
       " 0.05253962853190663]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:1\n",
      "Episode:2 Score:-1\n",
      "Episode:3 Score:-1\n",
      "Episode:4 Score:-1\n",
      "Episode:5 Score:-1\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.78, 0.6257795138864806)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)\n",
    "\n",
    "# Random Agent, before training   \n",
    "'''stolen from: https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb#scrollTo=xDHLMA6NFk95\n",
    "since the evaluate_policy function from this tutorial errored'''\n",
    "evaluate_policy(model, env, n_eval_episodes=100)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -0.74    |\n",
      "| time/              |          |\n",
      "|    fps             | 2609     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.76        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1822         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068495963 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.2         |\n",
      "|    explained_variance   | -0.0156      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.202        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 0.444        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1665         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074590263 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | -0.00738     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.165        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    value_loss           | 0.359        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.76       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1594        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008832283 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | -0.00284    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.345       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    value_loss           | 0.404       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1535         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121322535 |\n",
      "|    clip_fraction        | 0.069        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.000101     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.232        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    value_loss           | 0.424        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.72       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1500        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010833395 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0.000476    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.228       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 0.378       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.84       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1467        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011418421 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.16       |\n",
      "|    explained_variance   | -0.00611    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.186       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 0.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.86       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1449        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009752944 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | -0.00214    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    value_loss           | 0.402       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.72       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1444        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011493718 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | -0.00211    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    value_loss           | 0.376       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1441        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009866415 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.000285    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.365       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    value_loss           | 0.409       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.74       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1436        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008682967 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | -0.00518    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.246       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.58       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1434        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010202521 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | -0.0045     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.401       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.74       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1432        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009890384 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.000318    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    value_loss           | 0.445       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.78       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1430        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011615034 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | -0.00283    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.82       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1428        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007920627 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.07       |\n",
      "|    explained_variance   | 0.00072     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.249       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    value_loss           | 0.413       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.78        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1428         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061364034 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | -0.00188     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    value_loss           | 0.382        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.66       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1419        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009882891 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | -0.00434    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    value_loss           | 0.388       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1418         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068267444 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | -0.00144     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.228        |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00736     |\n",
      "|    value_loss           | 0.394        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.78        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1418         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084745325 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | -0.00621     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.22         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    value_loss           | 0.356        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.74       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1418        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010586428 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | -0.00159    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    value_loss           | 0.33        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.86       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1418        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008277015 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | -0.00174    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0958      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    value_loss           | 0.399       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.78        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1417         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106736645 |\n",
      "|    clip_fraction        | 0.0744       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | -0.00679     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.203        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00847     |\n",
      "|    value_loss           | 0.401        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.82       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1413        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008859366 |\n",
      "|    clip_fraction        | 0.0517      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.000713    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    value_loss           | 0.436       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.86       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1412        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009508489 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | -0.00699    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0862      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    value_loss           | 0.377       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.84       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1411        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003995356 |\n",
      "|    clip_fraction        | 0.00752     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | -0.00121    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    value_loss           | 0.376       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.68       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1411        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008142648 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | -0.00298    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.256       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    value_loss           | 0.403       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.68       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1411        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009606812 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | -0.00168    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    value_loss           | 0.395       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.78       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1411        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009482227 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | -0.00452    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0632      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.78       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1410        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011605844 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | -0.00253    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    value_loss           | 0.412       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.78       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1408        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009086939 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.00125     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.335       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    value_loss           | 0.429       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | -0.88     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1408      |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0129722 |\n",
      "|    clip_fraction        | 0.101     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.98     |\n",
      "|    explained_variance   | -0.00243  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.278     |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -0.00939  |\n",
      "|    value_loss           | 0.402     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.78        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1407         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131605165 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.000617     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.129        |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    value_loss           | 0.304        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.78       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013048362 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -0.00357    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    value_loss           | 0.389       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.64       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008562537 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.00155    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.083       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    value_loss           | 0.356       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.78       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012506476 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.00709    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.231       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    value_loss           | 0.366       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008883551 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -0.0014     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    value_loss           | 0.372       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.78        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1407         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086889565 |\n",
      "|    clip_fraction        | 0.0795       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | -0.00262     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.297        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00812     |\n",
      "|    value_loss           | 0.382        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.84       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011058981 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -0.00182    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.181       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    value_loss           | 0.392       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.72       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012258033 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.00233    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.74       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005946869 |\n",
      "|    clip_fraction        | 0.0268      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.000834    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.236       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 0.402       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009328717 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | -0.00615    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    value_loss           | 0.393       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.68       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010022102 |\n",
      "|    clip_fraction        | 0.0372      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -0.00088    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.128       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    value_loss           | 0.403       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.76       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007634813 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | -0.00353    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    value_loss           | 0.454       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | -0.88      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1406       |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 64         |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00797246 |\n",
      "|    clip_fraction        | 0.0566     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.5       |\n",
      "|    explained_variance   | -0.00501   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.214      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00654   |\n",
      "|    value_loss           | 0.386      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.82       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010839288 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -0.00663    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.197       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    value_loss           | 0.412       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.76        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1406         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051824246 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -0.000213    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.158        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    value_loss           | 0.415        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1406         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064056795 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | -0.00271     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.341        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    value_loss           | 0.398        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -0.76        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1407         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062636025 |\n",
      "|    clip_fraction        | 0.047        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.00196     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.23         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    value_loss           | 0.397        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011525968 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.000726    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    value_loss           | 0.381       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f989b111d00>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL\n",
    "#model.save('PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL\n",
    "#evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM YT - CLARA\n",
    "shower_path = os.path.join('Training', 'Saved Models', 'Shower_Model_PPO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(shower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(shower_path,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_policy(model,env,n_eval_episodes=10,render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.76, 0.6499230723708769)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Agent, after training                            \n",
    "'''stolen from: https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb#scrollTo=xDHLMA6NFk95\n",
    "since the evaluate_policy function from this tutorial errored'''\n",
    "\n",
    "\n",
    "'''Mean reward per episode, std of reward per episode returns'''\n",
    "\n",
    "evaluate_policy(model, env, n_eval_episodes=100)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MODEL ACTUALLY LEARNS!\\n\\n(mean shower length, variance in shower length)\\n(however i dont know why we re interested in shower length since the goal of our agent is to regulate the temperature)\\ntotal_timesteps = 20 000: (-57.76, 2.486443242867209)\\ntotal_timesteps = 100 000:(59.38, 0.9249864863877744)'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''MODEL ACTUALLY LEARNS!\n",
    "\n",
    "(mean shower length, variance in shower length)\n",
    "(however i dont know why we re interested in shower length since the goal of our agent is to regulate the temperature)\n",
    "total_timesteps = 20 000: (-57.76, 2.486443242867209)\n",
    "total_timesteps = 100 000:(59.38, 0.9249864863877744)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.23763499846199734\n"
     ]
    }
   ],
   "source": [
    "bleh = np.random.randn(1, 9)\n",
    "sft = np.exp(bleh)/np.sum(np.exp(bleh))\n",
    "print(np.argmax(sft))\n",
    "print(np.max(sft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12409718781736806, 0.012405218841902729, 0.005146497221804358, 0.5616135514282242, 0.3939891446264752, 0.47490561370025214, 0.10262597394999803, 0.1560173156794322, 4.185103944192127]\n",
      "[0.12409718781736806, 0.1560173156794322, 4.185103944192127, 0.3939891446264752, 0.5616135514282242, 0.012405218841902729, 0.10262597394999803, 0.005146497221804358, 0.47490561370025214]\n"
     ]
    }
   ],
   "source": [
    "bleh = [random.uniform(0, 0.628) for _ in range(8)]\n",
    "bleh.append(random.uniform(2, 5))\n",
    "\n",
    "sft = np.exp(bleh)/np.sum(np.exp(bleh))\n",
    "print(bleh)\n",
    "random.shuffle(bleh)\n",
    "print(bleh)\n",
    "# print(sft)\n",
    "# print(np.argmax(sft))\n",
    "# print(np.max(sft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01490203 0.01332718 0.01323079 0.02308109 0.01951902 0.02116409\n",
      " 0.01458547 0.01538538 0.86480497]\n"
     ]
    }
   ],
   "source": [
    "print(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05416693546890216, 0.11098288949254514, 0.06179192314618518, 0.02083836311468572, 1.0202686584283205, 0.10698712777203301, 0.13641039920419593, 0.10682346425104382, 0.004223949757622388]\n",
      "[0.033384989484911386, 0.06840266237400262, 0.03808453785745719, 0.012843416882351608, 0.6288274966740421, 0.06593993373948176, 0.08407453188263128, 0.065839062149092, 0.002603368956029949]\n",
      "0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "no_pieces = 9\n",
    "p_gold  = [0.0 for i in range(no_pieces-1)] + [1.0]\n",
    "random.shuffle(p_gold)\n",
    "\n",
    "\n",
    "noise_std = 0.1  \n",
    "p_noise = [np.abs(np.random.normal(scale = noise_std, loc = i)) for i in p_gold]\n",
    "smax = [i/np.sum(p_noise) for i in p_noise]\n",
    "print(p_noise)\n",
    "print(smax)\n",
    "print(sum(smax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-542090d83448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mUnoEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_pieces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# POSSIBLE ACTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'''for now we only decide for a coordinate'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Env' is not defined"
     ]
    }
   ],
   "source": [
    "class UnoEnv(Env, no_pieces, X,y):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # STATE\n",
    "        self.state = X[i]\n",
    "        \n",
    "        # POSSIBLE OBSERVATION\n",
    "        self.observation_space = Box(low=0, high=100, shape=(no_pieces,))  \n",
    " \n",
    "        # POSSIBLE ACTION\n",
    "        self.action_space = Discrete(self.no_pieces)\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        if action == y[i]:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "        \n",
    "        done = True\n",
    "\n",
    "        return reward, done\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
