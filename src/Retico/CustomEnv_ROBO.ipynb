{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building an Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # number of pentomino pieces\n",
    "        no_pieces = 9 # + 1 + 1 #pieces + uncertainty + lang team\n",
    "        \n",
    "        self.uncertainty_action = 10\n",
    "        self.lang_action = 11\n",
    "        \n",
    "        # ACTIONS\n",
    "        '''for now: we only decide for one coordinate --> no of actions = number of coordinates)\n",
    "        (for later: we only decide for one coordinate out of all absolute coordinates and moving coordinate, \n",
    "        boolean value expressing uncertainty)'''\n",
    "        self.action_space = Discrete(no_pieces)\n",
    "        \n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=0, high=100, shape=(no_pieces,))\n",
    "        \n",
    "        # POSSIBLE STATES\n",
    "        '''Set start state (in our case start state is the only state and here we need to get our training data in or \n",
    "        construct a random formula that will randomly generate possible scenarios each time the function is called.\n",
    "        for now: create random probabilities for 9 coordinates that add up to one\n",
    "        uplevel: do the same and make sure that all follow the true distribution which is p=1 for the gold_coordinate and p=0 for all others\n",
    "        uplevel: do the same + add possiblity for moving vector'''\n",
    "        no_pieces = 9\n",
    "        self.p_gold  = [0.0 for i in range(no_pieces-1)] + [1.0]\n",
    "        random.shuffle(p_gold)\n",
    "\n",
    "\n",
    "        noise_std = 0.1  \n",
    "        p_noise = [np.abs(np.random.normal(scale = noise_std, loc = i)) for i in p_gold]\n",
    "        smax = [i/np.sum(p_noise) for i in p_noise]\n",
    "\n",
    "        self.state = smax\n",
    " \n",
    "        \n",
    "    def step(self, action):\n",
    "        '''Our actions do not affect our state, because we only have one state, the start state. Also we don't need \n",
    "        the shower_length which represents the lenght of the sequence, but at the end we use it in the evalulation-\n",
    "        function soo .. dunno.\n",
    "        '''\n",
    "    \n",
    "\n",
    "        if action == np.argmax(self.p_gold):\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "        \n",
    "        # Check if sequence is done\n",
    "        '''we have a sequence of one state: the output that the other groups give us. based on that \n",
    "        we make a decision and a new round starts. so we don't need to count down the seconds of a 60min long\n",
    "        shower to know when a round is over.'''\n",
    "        done = True\n",
    "        \n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        '''Reset start state (output of previous groups) when new round starts (use \"random-formula\" that we need to \n",
    "        create above)'''\n",
    "        bleh = [random.uniform(0, 0.628) for _ in range(8)]\n",
    "        bleh.append(random.uniform(2, 5))\n",
    "\n",
    "        self.state = np.exp(bleh)/np.sum(np.exp(bleh))\n",
    "\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CLARA\n",
    "env.observation_space \n",
    "env.observation_space.sample()\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06366576, 0.05938566, 0.04329654, 0.06496438, 0.06436485,\n",
       "       0.05115506, 0.05863587, 0.05098671, 0.54354519])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-1\n",
      "Episode:2 Score:-1\n",
      "Episode:3 Score:-1\n",
      "Episode:4 Score:-1\n",
      "Episode:5 Score:-1\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkt/.local/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.0, 0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)\n",
    "\n",
    "# Random Agent, before training   \n",
    "'''stolen from: https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb#scrollTo=xDHLMA6NFk95\n",
    "since the evaluate_policy function from this tutorial errored'''\n",
    "evaluate_policy(model, env, n_eval_episodes=100)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -0.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | -0.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 417        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19942847 |\n",
      "|    clip_fraction        | 0.754      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.01      |\n",
      "|    explained_variance   | -0.000636  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.103      |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.112     |\n",
      "|    value_loss           | 0.454      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 0.36       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 450        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21008912 |\n",
      "|    clip_fraction        | 0.971      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.00184    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.256      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.188     |\n",
      "|    value_loss           | 0.952      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.84      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 477       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2343271 |\n",
      "|    clip_fraction        | 0.968     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.447    |\n",
      "|    explained_variance   | 0.00622   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.319     |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -0.176    |\n",
      "|    value_loss           | 0.852     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 501        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22602631 |\n",
      "|    clip_fraction        | 0.0815     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0537    |\n",
      "|    explained_variance   | -0.0158    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0875     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0739    |\n",
      "|    value_loss           | 0.313      |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 518           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042478798 |\n",
      "|    clip_fraction        | 0.00137       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0101       |\n",
      "|    explained_variance   | -0.0901       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000149     |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.00236      |\n",
      "|    value_loss           | 0.00679       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 527           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019934258 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00599      |\n",
      "|    explained_variance   | -0.0184       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.13e-05      |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    value_loss           | 0.00398       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 544       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.006    |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.45e-05  |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -4.01e-07 |\n",
      "|    value_loss           | 4.96e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 0.98     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 554      |\n",
      "|    iterations           | 9        |\n",
      "|    time_elapsed         | 33       |\n",
      "|    total_timesteps      | 18432    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00605 |\n",
      "|    explained_variance   | nan      |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 2.02e-05 |\n",
      "|    n_updates            | 80       |\n",
      "|    policy_gradient_loss | -6.7e-08 |\n",
      "|    value_loss           | 4.31e-05 |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 555           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 36            |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013169996 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00447      |\n",
      "|    explained_variance   | -0.0211       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.74e-05      |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.000694     |\n",
      "|    value_loss           | 0.002         |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 548       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00425  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.06e-05  |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -3.27e-07 |\n",
      "|    value_loss           | 3.39e-05  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 550           |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 44            |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020646345 |\n",
      "|    clip_fraction        | 0.00142       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00291      |\n",
      "|    explained_variance   | -0.0114       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.44e-05      |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.00219      |\n",
      "|    value_loss           | 0.00597       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 552       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0028   |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.45e-06  |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -1.54e-07 |\n",
      "|    value_loss           | 2.74e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 1        |\n",
      "| time/                   |          |\n",
      "|    fps                  | 544      |\n",
      "|    iterations           | 14       |\n",
      "|    time_elapsed         | 52       |\n",
      "|    total_timesteps      | 28672    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00274 |\n",
      "|    explained_variance   | nan      |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 9.47e-06 |\n",
      "|    n_updates            | 130      |\n",
      "|    policy_gradient_loss | -2e-08   |\n",
      "|    value_loss           | 2.14e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 542       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00274  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5e-06     |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -8.55e-09 |\n",
      "|    value_loss           | 1.67e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 546       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00273  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.85e-06  |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -5.96e-08 |\n",
      "|    value_loss           | 1.31e-05  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 542           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 64            |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020406803 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00169      |\n",
      "|    explained_variance   | -0.00434      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.81e-05      |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.000693     |\n",
      "|    value_loss           | 0.00199       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 540           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 68            |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014307135 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00108      |\n",
      "|    explained_variance   | -0.00292      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.29e-05      |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.00069      |\n",
      "|    value_loss           | 0.002         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 543           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017089711 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000711     |\n",
      "|    explained_variance   | -0.00269      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.01e-05      |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000691     |\n",
      "|    value_loss           | 0.002         |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 541       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 75        |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000706 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.62e-06  |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -3.47e-08 |\n",
      "|    value_loss           | 5.81e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 540       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000711 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.1e-06   |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -4.89e-09 |\n",
      "|    value_loss           | 3.53e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 538       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000707 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.15e-06  |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -8.53e-09 |\n",
      "|    value_loss           | 2.83e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 537       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000701 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.76e-07  |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -5.19e-09 |\n",
      "|    value_loss           | 2.14e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 535       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000693 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.59e-07  |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -1.19e-08 |\n",
      "|    value_loss           | 1.76e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 532       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 96        |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000685 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.12e-07  |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | 5.81e-09  |\n",
      "|    value_loss           | 1.45e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 536       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000675 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.24e-07  |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -3.32e-08 |\n",
      "|    value_loss           | 1.36e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 536       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000662 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.88e-07  |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | 2.6e-09   |\n",
      "|    value_loss           | 1.25e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 538       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000658 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.05e-07  |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | 9.25e-09  |\n",
      "|    value_loss           | 1.09e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 543       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000646 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.42e-07  |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -2.17e-08 |\n",
      "|    value_loss           | 1.14e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 546       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000628 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.78e-07  |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -1.55e-08 |\n",
      "|    value_loss           | 1.07e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 548       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000612 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.87e-07  |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | 2.1e-08   |\n",
      "|    value_loss           | 1.05e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 548       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 119       |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000609 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.27e-07  |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | 1.56e-08  |\n",
      "|    value_loss           | 9.75e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 550       |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 122       |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000597 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.34e-07  |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -4.6e-08  |\n",
      "|    value_loss           | 9.35e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 553       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 125       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000571 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.18e-07  |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -4.63e-08 |\n",
      "|    value_loss           | 8.4e-07   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 555       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 129       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000543 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.36e-07  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -6.36e-09 |\n",
      "|    value_loss           | 7.39e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 558       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 131       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000521 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.94e-07  |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -4.18e-08 |\n",
      "|    value_loss           | 7.41e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 561       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 134       |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00049  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.03e-07  |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -5.02e-08 |\n",
      "|    value_loss           | 8.22e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 564       |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 137       |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000467 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.82e-07  |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | -1.12e-08 |\n",
      "|    value_loss           | 6.05e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 565       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 141       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000442 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.3e-08   |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -5.95e-08 |\n",
      "|    value_loss           | 7.1e-07   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 566       |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 144       |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000423 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.37e-07  |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | -5.42e-08 |\n",
      "|    value_loss           | 5.21e-07  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 1            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 568          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002687657 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000236    |\n",
      "|    explained_variance   | 0.000421     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00012      |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.000693    |\n",
      "|    value_loss           | 0.00207      |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 569       |\n",
      "|    iterations           | 42        |\n",
      "|    time_elapsed         | 150       |\n",
      "|    total_timesteps      | 86016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000217 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.51e-07  |\n",
      "|    n_updates            | 410       |\n",
      "|    policy_gradient_loss | -5.33e-08 |\n",
      "|    value_loss           | 3.87e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 571       |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 154       |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000222 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.36e-07  |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -3.04e-09 |\n",
      "|    value_loss           | 3.69e-07  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 1        |\n",
      "| time/                   |          |\n",
      "|    fps                  | 571      |\n",
      "|    iterations           | 44       |\n",
      "|    time_elapsed         | 157      |\n",
      "|    total_timesteps      | 90112    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00022 |\n",
      "|    explained_variance   | nan      |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 1.73e-07 |\n",
      "|    n_updates            | 430      |\n",
      "|    policy_gradient_loss | 1.88e-08 |\n",
      "|    value_loss           | 3.3e-07  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 573       |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 160       |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000219 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.7e-07   |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | 4.43e-08  |\n",
      "|    value_loss           | 3.48e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 574       |\n",
      "|    iterations           | 46        |\n",
      "|    time_elapsed         | 163       |\n",
      "|    total_timesteps      | 94208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000216 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.9e-07   |\n",
      "|    n_updates            | 450       |\n",
      "|    policy_gradient_loss | 1.42e-08  |\n",
      "|    value_loss           | 3.02e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 575       |\n",
      "|    iterations           | 47        |\n",
      "|    time_elapsed         | 167       |\n",
      "|    total_timesteps      | 96256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000214 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -1.26e-07 |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | -6.81e-08 |\n",
      "|    value_loss           | 2.97e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 577       |\n",
      "|    iterations           | 48        |\n",
      "|    time_elapsed         | 170       |\n",
      "|    total_timesteps      | 98304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000211 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.3e-08   |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | -3.63e-08 |\n",
      "|    value_loss           | 2.73e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 578       |\n",
      "|    iterations           | 49        |\n",
      "|    time_elapsed         | 173       |\n",
      "|    total_timesteps      | 100352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000209 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.17e-07  |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | -1.73e-08 |\n",
      "|    value_loss           | 2.71e-07  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f6c5d805390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL\n",
    "#model.save('PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL\n",
    "#evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM YT - CLARA\n",
    "shower_path = os.path.join('Training', 'Saved Models', 'Shower_Model_PPO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkt/.local/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:276: UserWarning: Path 'Training/Saved Models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "model.save(shower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(shower_path,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_policy(model,env,n_eval_episodes=10,render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkt/.local/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Agent, after training                            \n",
    "'''stolen from: https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb#scrollTo=xDHLMA6NFk95\n",
    "since the evaluate_policy function from this tutorial errored'''\n",
    "evaluate_policy(model, env, n_eval_episodes=100)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MODEL ACTUALLY LEARNS!\\n\\n(mean shower length, variance in shower length)\\n(however i dont know why we re interested in shower length since the goal of our agent is to regulate the temperature)\\ntotal_timesteps = 20 000: (-57.76, 2.486443242867209)\\ntotal_timesteps = 100 000:(59.38, 0.9249864863877744)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''MODEL ACTUALLY LEARNS!\n",
    "\n",
    "(mean shower length, variance in shower length)\n",
    "(however i dont know why we re interested in shower length since the goal of our agent is to regulate the temperature)\n",
    "total_timesteps = 20 000: (-57.76, 2.486443242867209)\n",
    "total_timesteps = 100 000:(59.38, 0.9249864863877744)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0.6175825595351309\n"
     ]
    }
   ],
   "source": [
    "bleh = np.random.randn(1, 9)\n",
    "sft = np.exp(bleh)/np.sum(np.exp(bleh))\n",
    "print(np.argmax(sft))\n",
    "print(np.max(sft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12409718781736806, 0.012405218841902729, 0.005146497221804358, 0.5616135514282242, 0.3939891446264752, 0.47490561370025214, 0.10262597394999803, 0.1560173156794322, 4.185103944192127]\n",
      "[0.12409718781736806, 0.1560173156794322, 4.185103944192127, 0.3939891446264752, 0.5616135514282242, 0.012405218841902729, 0.10262597394999803, 0.005146497221804358, 0.47490561370025214]\n"
     ]
    }
   ],
   "source": [
    "bleh = [random.uniform(0, 0.628) for _ in range(8)]\n",
    "bleh.append(random.uniform(2, 5))\n",
    "\n",
    "sft = np.exp(bleh)/np.sum(np.exp(bleh))\n",
    "print(bleh)\n",
    "random.shuffle(bleh)\n",
    "print(bleh)\n",
    "# print(sft)\n",
    "# print(np.argmax(sft))\n",
    "# print(np.max(sft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01490203 0.01332718 0.01323079 0.02308109 0.01951902 0.02116409\n",
      " 0.01458547 0.01538538 0.86480497]\n"
     ]
    }
   ],
   "source": [
    "print(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05416693546890216, 0.11098288949254514, 0.06179192314618518, 0.02083836311468572, 1.0202686584283205, 0.10698712777203301, 0.13641039920419593, 0.10682346425104382, 0.004223949757622388]\n",
      "[0.033384989484911386, 0.06840266237400262, 0.03808453785745719, 0.012843416882351608, 0.6288274966740421, 0.06593993373948176, 0.08407453188263128, 0.065839062149092, 0.002603368956029949]\n",
      "0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "no_pieces = 9\n",
    "p_gold  = [0.0 for i in range(no_pieces-1)] + [1.0]\n",
    "random.shuffle(p_gold)\n",
    "\n",
    "\n",
    "noise_std = 0.1  \n",
    "p_noise = [np.abs(np.random.normal(scale = noise_std, loc = i)) for i in p_gold]\n",
    "smax = [i/np.sum(p_noise) for i in p_noise]\n",
    "print(p_noise)\n",
    "print(smax)\n",
    "print(sum(smax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('anlp2021')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "72ed6c992ba7fdd0ca8e67b9e6bb1892b67ffbcbb0d6c7cc95f752a3faeb832f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
