{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.6.0-py3-none-any.whl (177 kB)\n",
      "Collecting gym==0.21\n",
      "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
      "Requirement already satisfied: pandas in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from stable-baselines3[extra]) (1.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from stable-baselines3[extra]) (1.19.2)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.3-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "Collecting torch>=1.11\n",
      "  Downloading torch-1.12.1-cp38-cp38-win_amd64.whl (161.9 MB)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting pillow\n",
      "  Downloading Pillow-9.2.0-cp38-cp38-win_amd64.whl (3.3 MB)\n",
      "Collecting protobuf~=3.19.0\n",
      "  Using cached protobuf-3.19.4-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "Collecting ale-py==0.7.4\n",
      "  Downloading ale_py-0.7.4-cp38-cp38-win_amd64.whl (904 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "Collecting autorom[accept-rom-license]~=0.4.2\n",
      "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.9.2-cp38-cp38-win_amd64.whl (246 kB)\n",
      "Collecting importlib-metadata>=4.10.0\n",
      "  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\basti\\appdata\\roaming\\python\\python38\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.27.1)\n",
      "Requirement already satisfied: click in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.64.0)\n",
      "Collecting AutoROM.accept-rom-license\n",
      "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\basti\\appdata\\roaming\\python\\python38\\site-packages (from importlib-metadata>=4.10.0->ale-py==0.7.4->stable-baselines3[extra]) (3.6.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.35.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.46.1)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (61.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.4)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.6.15)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->stable-baselines3[extra]) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from click->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.4.5)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-win_amd64.whl (55 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (21.3)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.37.1-py3-none-any.whl (957 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\basti\\anaconda3\\envs\\hri\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
      "Building wheels for collected packages: gym, AutoROM.accept-rom-license\n",
      "  Building wheel for gym (setup.py): started\n",
      "  Building wheel for gym (setup.py): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616825 sha256=0ac2c1724d0893ba87fcd88db8988e4a691099520ec2e65ff4be3d6e0296d938\n",
      "  Stored in directory: c:\\users\\basti\\appdata\\local\\pip\\cache\\wheels\\27\\6d\\b3\\a3a6e10704795c9b9000f1ab2dc480dfe7bed42f5972806e73\n",
      "  Building wheel for AutoROM.accept-rom-license (PEP 517): started\n",
      "  Building wheel for AutoROM.accept-rom-license (PEP 517): finished with status 'done'\n",
      "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=446447 sha256=5cd0d31f3964ee7b8c25a30d062edb59a379230f7f14a2b92eafaa8dd62b1b6f\n",
      "  Stored in directory: c:\\users\\basti\\appdata\\local\\pip\\cache\\wheels\\51\\08\\c5\\28b973078691a3f8baf99fcaec1ed8f0e05ef6e54d2390212c\n",
      "Successfully built gym AutoROM.accept-rom-license\n",
      "Installing collected packages: oauthlib, requests-oauthlib, pillow, kiwisolver, importlib-metadata, fonttools, cycler, cloudpickle, werkzeug, torch, tensorboard-plugin-wit, tensorboard-data-server, protobuf, matplotlib, markdown, gym, google-auth-oauthlib, AutoROM.accept-rom-license, autorom, absl-py, tensorboard, stable-baselines3, psutil, opencv-python, ale-py\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "Successfully installed AutoROM.accept-rom-license-0.4.2 absl-py-1.2.0 ale-py-0.7.4 autorom-0.4.2 cloudpickle-2.2.0 cycler-0.11.0 fonttools-4.37.1 google-auth-oauthlib-0.4.6 gym-0.21.0 importlib-metadata-4.12.0 kiwisolver-1.4.4 markdown-3.4.1 matplotlib-3.5.3 oauthlib-3.2.0 opencv-python-4.6.0.66 pillow-9.2.0 protobuf-3.19.4 psutil-5.9.2 requests-oauthlib-1.3.1 stable-baselines3-1.6.0 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torch-1.12.1 werkzeug-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import stable_baselines3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Building an Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # number of pentomino pieces\n",
    "        no_pieces = 9 # + 1 + 1 #pieces + uncertainty + lang team\n",
    "        \n",
    "        self.uncertainty_action = 10\n",
    "        self.lang_action = 11\n",
    "        \n",
    "        # ACTIONS\n",
    "        '''for now: we only decide for one coordinate --> no of actions = number of coordinates)\n",
    "        (for later: we only decide for one coordinate out of all absolute coordinates and moving coordinate, \n",
    "        boolean value expressing uncertainty)'''\n",
    "        self.action_space = Discrete(no_pieces)\n",
    "        \n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=0, high=100, shape=(no_pieces,))\n",
    "        \n",
    "        # POSSIBLE STATES\n",
    "        '''Set start state (in our case start state is the only state and here we need to get our training data in or \n",
    "        construct a random formula that will randomly generate possible scenarios each time the function is called.\n",
    "        for now: create random probabilities for 9 coordinates that add up to one\n",
    "        uplevel: do the same and make sure that all follow the true distribution which is p=1 for the gold_coordinate and p=0 for all others\n",
    "        uplevel: do the same + add possiblity for moving vector'''\n",
    "        no_pieces = 9\n",
    "        self.p_gold  = [0.0 for i in range(no_pieces-1)] + [1.0]\n",
    "        random.shuffle(self.p_gold)\n",
    "\n",
    "\n",
    "        noise_std = 0.1  \n",
    "        p_noise = [np.abs(np.random.normal(scale = noise_std, loc = i)) for i in self.p_gold]\n",
    "        smax = [i/np.sum(p_noise) for i in p_noise]\n",
    "\n",
    "        self.state = smax\n",
    " \n",
    "        \n",
    "    def step(self, action):\n",
    "        '''Our actions do not affect our state, because we only have one state, the start state. Also we don't need \n",
    "        the shower_length which represents the lenght of the sequence, but at the end we use it in the evalulation-\n",
    "        function soo .. dunno.\n",
    "        '''\n",
    "    \n",
    "\n",
    "        if action == np.argmax(self.p_gold):\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "        \n",
    "        # Check if sequence is done\n",
    "        '''we have a sequence of one state: the output that the other groups give us. based on that \n",
    "        we make a decision and a new round starts. so we don't need to count down the seconds of a 60min long\n",
    "        shower to know when a round is over.'''\n",
    "        done = True\n",
    "        \n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        '''Reset start state (output of previous groups) when new round starts (use \"random-formula\" that we need to \n",
    "        create above)'''\n",
    "        bleh = [random.uniform(0, 0.628) for _ in range(8)]\n",
    "        bleh.append(random.uniform(2, 5))\n",
    "\n",
    "        self.state = np.exp(bleh)/np.sum(np.exp(bleh))\n",
    "\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env=ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CLARA\n",
    "env.observation_space \n",
    "env.observation_space.sample()\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.01074775, 0.01684012, 0.01446465, 0.01308205, 0.01130682,\n       0.01182561, 0.0121615 , 0.01082418, 0.89874732])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:1\n",
      "Episode:2 Score:-1\n",
      "Episode:3 Score:-1\n",
      "Episode:4 Score:-1\n",
      "Episode:5 Score:-1\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Basti\\anaconda3\\envs\\hri\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "(1.0, 0.0)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)\n",
    "\n",
    "# Random Agent, before training   \n",
    "'''stolen from: https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb#scrollTo=xDHLMA6NFk95\n",
    "since the evaluate_policy function from this tutorial errored'''\n",
    "evaluate_policy(model, env, n_eval_episodes=100)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -0.74    |\n",
      "| time/              |          |\n",
      "|    fps             | 1274     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | -0.36      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 878        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17418805 |\n",
      "|    clip_fraction        | 0.768      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.01      |\n",
      "|    explained_variance   | -0.00712   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0688     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.105     |\n",
      "|    value_loss           | 0.411      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 0.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 835        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21426195 |\n",
      "|    clip_fraction        | 0.973      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | -0.0105    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.287      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.189     |\n",
      "|    value_loss           | 0.959      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 0.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 772        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26557612 |\n",
      "|    clip_fraction        | 0.969      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.415     |\n",
      "|    explained_variance   | 0.0105     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.263      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.179     |\n",
      "|    value_loss           | 0.873      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 615        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20166221 |\n",
      "|    clip_fraction        | 0.075      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.051     |\n",
      "|    explained_variance   | -0.0303    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0705     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0689    |\n",
      "|    value_loss           | 0.294      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 1            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005806598 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00995     |\n",
      "|    explained_variance   | -0.104       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000108    |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 0.0107       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 1            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002292374 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00589     |\n",
      "|    explained_variance   | -0.00655     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86e-05     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 0.00394      |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.98      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 456       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00583  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.76e-06  |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -3.52e-08 |\n",
      "|    value_loss           | 1.31e-05  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 457           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 40            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011907297 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00445      |\n",
      "|    explained_variance   | -0.0138       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.44e-05      |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000695     |\n",
      "|    value_loss           | 0.00198       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 1            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001274808 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0032      |\n",
      "|    explained_variance   | 0.00556      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.89e-05     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000701    |\n",
      "|    value_loss           | 0.00195      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 466           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 48            |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014321331 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0022       |\n",
      "|    explained_variance   | 2.38e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.56e-06      |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.000699     |\n",
      "|    value_loss           | 0.00196       |\n",
      "-------------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 1        |\n",
      "| time/                   |          |\n",
      "|    fps                  | 467      |\n",
      "|    iterations           | 12       |\n",
      "|    time_elapsed         | 52       |\n",
      "|    total_timesteps      | 24576    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00207 |\n",
      "|    explained_variance   | nan      |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 5.97e-06 |\n",
      "|    n_updates            | 110      |\n",
      "|    policy_gradient_loss | -3.1e-07 |\n",
      "|    value_loss           | 1.02e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 468       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00203  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.52e-06  |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -7.93e-09 |\n",
      "|    value_loss           | 9.59e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 464       |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00202  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.51e-06  |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -1.13e-08 |\n",
      "|    value_loss           | 8.49e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 464       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.002    |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.93e-06  |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -5.46e-09 |\n",
      "|    value_loss           | 6.96e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 465       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 70        |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00198  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.75e-06  |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -3.05e-08 |\n",
      "|    value_loss           | 6.38e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 467       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00195  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.8e-06   |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -5.43e-08 |\n",
      "|    value_loss           | 5.07e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 470       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00191  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.15e-06  |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -2.95e-08 |\n",
      "|    value_loss           | 4.46e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 471       |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 82        |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00188  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.74e-06  |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -4.55e-08 |\n",
      "|    value_loss           | 4.27e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 471       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00183  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.74e-06  |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -3.71e-08 |\n",
      "|    value_loss           | 3.41e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 471       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0018   |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.31e-06  |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -2.28e-08 |\n",
      "|    value_loss           | 3.08e-06  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 1            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 473          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007879705 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.000736    |\n",
      "|    explained_variance   | -0.00168     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.42e-07     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    value_loss           | 0.00399      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 475           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 99            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015643699 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000426     |\n",
      "|    explained_variance   | 0.00653       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.14e-05      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000694     |\n",
      "|    value_loss           | 0.00198       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 475       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0004   |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.92e-06  |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -5.22e-09 |\n",
      "|    value_loss           | 7.52e-06  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 1        |\n",
      "| time/                   |          |\n",
      "|    fps                  | 476      |\n",
      "|    iterations           | 25       |\n",
      "|    time_elapsed         | 107      |\n",
      "|    total_timesteps      | 51200    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.0004  |\n",
      "|    explained_variance   | nan      |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 2.52e-06 |\n",
      "|    n_updates            | 240      |\n",
      "|    policy_gradient_loss | 7.39e-09 |\n",
      "|    value_loss           | 3.84e-06 |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1             |\n",
      "|    ep_rew_mean          | 1             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 476           |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 111           |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019915338 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000256     |\n",
      "|    explained_variance   | -0.00121      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.49e-05      |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -0.000692     |\n",
      "|    value_loss           | 0.00201       |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 474       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000247 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.28e-06  |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | 4.62e-09  |\n",
      "|    value_loss           | 4.96e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 476       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 120       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000247 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.17e-07  |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -8.76e-10 |\n",
      "|    value_loss           | 2.41e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 477       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 124       |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000247 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.1e-06   |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -5.36e-09 |\n",
      "|    value_loss           | 2.18e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 478       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 128       |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000246 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.18e-07  |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | 4.32e-10  |\n",
      "|    value_loss           | 1.92e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 480       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 132       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000245 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.75e-07  |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -9.6e-09  |\n",
      "|    value_loss           | 1.85e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 481       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 136       |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000244 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.98e-07  |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -1.41e-09 |\n",
      "|    value_loss           | 1.81e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 483       |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 139       |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000243 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.35e-07  |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -5.44e-09 |\n",
      "|    value_loss           | 1.63e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 485       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 143       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000243 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.43e-07  |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | 6.68e-09  |\n",
      "|    value_loss           | 1.58e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 487       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 147       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000242 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.55e-07  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -1.46e-09 |\n",
      "|    value_loss           | 1.46e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 489       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 150       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000241 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.38e-07  |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | 1.03e-08  |\n",
      "|    value_loss           | 1.43e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 491       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 154       |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000239 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.21e-07  |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | 1.96e-08  |\n",
      "|    value_loss           | 1.31e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 493       |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 157       |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000237 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.51e-07  |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | 1.65e-08  |\n",
      "|    value_loss           | 1.2e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 494       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 161       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000235 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.32e-07  |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -6.38e-08 |\n",
      "|    value_loss           | 9.93e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 497       |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 164       |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000233 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.67e-07  |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | 6.88e-09  |\n",
      "|    value_loss           | 9.61e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 498       |\n",
      "|    iterations           | 41        |\n",
      "|    time_elapsed         | 168       |\n",
      "|    total_timesteps      | 83968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000233 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.03e-07  |\n",
      "|    n_updates            | 400       |\n",
      "|    policy_gradient_loss | -1.68e-08 |\n",
      "|    value_loss           | 9.01e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 500       |\n",
      "|    iterations           | 42        |\n",
      "|    time_elapsed         | 171       |\n",
      "|    total_timesteps      | 86016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000233 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.66e-07  |\n",
      "|    n_updates            | 410       |\n",
      "|    policy_gradient_loss | -1.59e-09 |\n",
      "|    value_loss           | 8.26e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 501       |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 175       |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000231 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.85e-07  |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | 1.7e-09   |\n",
      "|    value_loss           | 7.21e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 504       |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 178       |\n",
      "|    total_timesteps      | 90112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000228 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.77e-07  |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | 5.75e-08  |\n",
      "|    value_loss           | 7.07e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 505       |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 182       |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000225 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.89e-07  |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | 9.81e-09  |\n",
      "|    value_loss           | 7.2e-07   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 506       |\n",
      "|    iterations           | 46        |\n",
      "|    time_elapsed         | 185       |\n",
      "|    total_timesteps      | 94208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000223 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.22e-07  |\n",
      "|    n_updates            | 450       |\n",
      "|    policy_gradient_loss | -7.47e-09 |\n",
      "|    value_loss           | 4.41e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 506       |\n",
      "|    iterations           | 47        |\n",
      "|    time_elapsed         | 190       |\n",
      "|    total_timesteps      | 96256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000222 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.71e-07  |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | -2.24e-09 |\n",
      "|    value_loss           | 4.89e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 506       |\n",
      "|    iterations           | 48        |\n",
      "|    time_elapsed         | 194       |\n",
      "|    total_timesteps      | 98304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00022  |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.51e-09  |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | -5.42e-08 |\n",
      "|    value_loss           | 4.38e-07  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 508       |\n",
      "|    iterations           | 49        |\n",
      "|    time_elapsed         | 197       |\n",
      "|    total_timesteps      | 100352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000216 |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.2e-07   |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | 2.4e-08   |\n",
      "|    value_loss           | 4.5e-07   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<stable_baselines3.ppo.ppo.PPO at 0x27d2e81b7f0>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#ORIGINAL\n",
    "#model.save('PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#ORIGINAL\n",
    "#evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# FROM YT - CLARA\n",
    "shower_path = os.path.join('Training', 'Saved Models', 'Shower_Model_PPO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save(shower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(shower_path,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#evaluate_policy(model,env,n_eval_episodes=10,render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1.0, 0.0)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Agent, after training                            \n",
    "'''stolen from: https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb#scrollTo=xDHLMA6NFk95\n",
    "since the evaluate_policy function from this tutorial errored'''\n",
    "evaluate_policy(model, env, n_eval_episodes=100)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'MODEL ACTUALLY LEARNS!\\n\\n(mean shower length, variance in shower length)\\n(however i dont know why we re interested in shower length since the goal of our agent is to regulate the temperature)\\ntotal_timesteps = 20 000: (-57.76, 2.486443242867209)\\ntotal_timesteps = 100 000:(59.38, 0.9249864863877744)'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''MODEL ACTUALLY LEARNS!\n",
    "\n",
    "(mean shower length, variance in shower length)\n",
    "(however i dont know why we re interested in shower length since the goal of our agent is to regulate the temperature)\n",
    "total_timesteps = 20 000: (-57.76, 2.486443242867209)\n",
    "total_timesteps = 100 000:(59.38, 0.9249864863877744)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0.4760460442234847\n"
     ]
    }
   ],
   "source": [
    "bleh = np.random.randn(1, 9)\n",
    "sft = np.exp(bleh)/np.sum(np.exp(bleh))\n",
    "print(np.argmax(sft))\n",
    "print(np.max(sft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5358925115066222, 0.2706150227228086, 0.1720668895990129, 0.4377482911256423, 0.10029355568712371, 0.4589329246155352, 0.1346392009510646, 0.31398168912080665, 4.823779320462388]\n",
      "[4.823779320462388, 0.1346392009510646, 0.1720668895990129, 0.5358925115066222, 0.2706150227228086, 0.31398168912080665, 0.4589329246155352, 0.10029355568712371, 0.4377482911256423]\n"
     ]
    }
   ],
   "source": [
    "bleh = [random.uniform(0, 0.628) for _ in range(8)]\n",
    "bleh.append(random.uniform(2, 5))\n",
    "\n",
    "sft = np.exp(bleh)/np.sum(np.exp(bleh))\n",
    "print(bleh)\n",
    "random.shuffle(bleh)\n",
    "print(bleh)\n",
    "# print(sft)\n",
    "# print(np.argmax(sft))\n",
    "# print(np.max(sft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0126224  0.00968129 0.00877272 0.01144244 0.00816514 0.01168742\n",
      " 0.00845045 0.01011038 0.91906775]\n"
     ]
    }
   ],
   "source": [
    "print(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17797209551960547, 0.023450190705157983, 0.22445618413934976, 0.12561120388192143, 0.07265502721625859, 1.035757304976535, 0.0978092801319897, 0.13646983626791512, 0.15077125988059803]\n",
      "[0.08702994603861741, 0.011467352933653379, 0.10976108100907125, 0.061425001845219755, 0.035528957950426016, 0.5064945833111325, 0.04782961254184567, 0.06673497017394638, 0.07372849419608776]\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "no_pieces = 9\n",
    "p_gold  = [0.0 for i in range(no_pieces-1)] + [1.0]\n",
    "random.shuffle(p_gold)\n",
    "\n",
    "\n",
    "noise_std = 0.1  \n",
    "p_noise = [np.abs(np.random.normal(scale = noise_std, loc = i)) for i in p_gold]\n",
    "smax = [i/np.sum(p_noise) for i in p_noise]\n",
    "print(p_noise)\n",
    "print(smax)\n",
    "print(sum(smax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}